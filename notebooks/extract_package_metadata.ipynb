{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce1f386-a0a0-4f12-8808-48d6c3ed8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\besis\\AppData\\Local\\Temp\\ipykernel_7804\\3564904754.py:106: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: np.nan if x in [None, '', {}, []] else x)\n",
      "2024-10-14 20:42:20,883 - INFO - Data extraction complete. CSV file saved at ../data/metadata/raw\\extracted_metadata.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete.\n",
      "Empty DataFrame\n",
      "Columns: [id, name, version, authors, email, summary, description, date, files, test_files, autorequire, executables, require_paths, dependencies, runtime_dependencies, development_dependencies, extensions, requirements, homepage, metadata, licenses, platform, required_ruby_version, required_rubygems_version, rubygems_version, extra_rdoc_files, rdoc_options, specification_version, cert_chain, signing_key, post_install_message]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 메타데이터 추출 함수\n",
    "def extract_package_metadata(input_path=\"../data/package\", \n",
    "                             output_path=\"../data/metadata/raw\", \n",
    "                             output_filename=\"extracted_metadata.csv\"):\n",
    "    \n",
    "    # 31개의 컬럼 정의\n",
    "    columns = ['id', 'name', 'version', 'authors', 'email', 'summary', 'description', 'date',\n",
    "               'files', 'test_files', 'autorequire', 'executables', 'require_paths',\n",
    "               'dependencies', 'runtime_dependencies', 'development_dependencies', 'extensions', 'requirements',\n",
    "               'homepage', 'metadata', 'licenses',\n",
    "               'platform', 'required_ruby_version', 'required_rubygems_version', 'rubygems_version',\n",
    "               'extra_rdoc_files', 'rdoc_options', 'specification_version',\n",
    "               'cert_chain', 'signing_key', 'post_install_message']\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".gem\"):\n",
    "                gem_file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with tarfile.open(gem_file_path, 'r') as gem_file:\n",
    "                        # metadata.gz 파일을 추출\n",
    "                        metadata_gz = next((gem_file.extractfile(member) for member in gem_file.getmembers() if member.name.endswith(\"metadata.gz\")), None)\n",
    "                        if metadata_gz is None:\n",
    "                            logging.warning(f\"metadata.gz not found in {gem_file_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # metadata.gz 파일을 gzip 해제\n",
    "                        with gzip.GzipFile(fileobj=metadata_gz) as f:\n",
    "                            metadata_content = f.read()\n",
    "\n",
    "                        # YAML 파싱 전에 특수 태그 제거 (replace를 한 번에 처리)\n",
    "                        tags_to_remove = [\"!ruby/object:Gem::Specification\", \"!ruby/object:Gem::Version\", \n",
    "                                          \"!ruby/object:Gem::Dependency\", \"!ruby/object:Gem::Requirement\"]\n",
    "                        metadata_text = metadata_content.decode(\"utf-8\")\n",
    "                        for tag in tags_to_remove:\n",
    "                            metadata_text = metadata_text.replace(tag, \"\")\n",
    "\n",
    "                        # YAML 파싱\n",
    "                        metadata = yaml.safe_load(metadata_text)\n",
    "\n",
    "                        # 각 특성 추출 및 null 값 처리\n",
    "                        row = []\n",
    "                        name = metadata.get('name', '')\n",
    "                        version = metadata.get('version', '')\n",
    "                        # id 컬럼 생성\n",
    "                        id_value = f\"{name}-{version}\" if name and version else np.nan\n",
    "                        row.append(id_value)  # id 추가\n",
    "                        \n",
    "                        for col in columns[1:]:  # 이미 id는 추가했으므로 나머지 컬럼만 처리\n",
    "                            value = metadata.get(col, np.nan)  # 기본적으로 np.nan으로 처리\n",
    "                            if isinstance(value, list) and not value:  # 빈 리스트 처리\n",
    "                                value = np.nan\n",
    "                            if isinstance(value, str) and (not value.strip() or value in [' ', '']):  # 빈 문자열, 띄어쓰기, 공백 처리\n",
    "                                value = np.nan\n",
    "                            if value is None:  # None 값도 np.nan으로 처리\n",
    "                                value = np.nan\n",
    "                            row.append(value)\n",
    "\n",
    "                        # dependencies를 runtime과 development로 분리하여 추출\n",
    "                        dependencies = metadata.get('dependencies', np.nan)\n",
    "                        runtime_dependencies = []\n",
    "                        development_dependencies = []\n",
    "\n",
    "                        if dependencies is not np.nan:\n",
    "                            for dep in dependencies:\n",
    "                                dep_type = dep.get('type', '')\n",
    "                                if dep_type == ':runtime':\n",
    "                                    runtime_dependencies.append(dep)\n",
    "                                elif dep_type == ':development':\n",
    "                                    development_dependencies.append(dep)\n",
    "\n",
    "                            if not runtime_dependencies:\n",
    "                                runtime_dependencies = np.nan\n",
    "                            if not development_dependencies:\n",
    "                                development_dependencies = np.nan\n",
    "                        else:\n",
    "                            runtime_dependencies = np.nan\n",
    "                            development_dependencies = np.nan\n",
    "\n",
    "                        # dependencies를 원본 그대로 유지하고, 분류된 것을 각각 추가\n",
    "                        row[columns.index('dependencies')] = dependencies\n",
    "                        row[columns.index('runtime_dependencies')] = runtime_dependencies\n",
    "                        row[columns.index('development_dependencies')] = development_dependencies\n",
    "\n",
    "                        data.append(row)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {gem_file_path}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # 각 요소를 검사하여 None, 빈 문자열, 빈 리스트 등을 np.nan으로 통일\n",
    "    df = df.applymap(lambda x: np.nan if x in [None, '', {}, []] else x)\n",
    "\n",
    "    # DataFrame을 CSV 파일로 저장\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    df.to_csv(os.path.join(output_path, output_filename), index=False)\n",
    "\n",
    "    logging.info(f\"Data extraction complete. CSV file saved at {os.path.join(output_path, output_filename)}\")\n",
    "    \n",
    "    # 데이터 추출 완료 메시지 출력\n",
    "    print(\"Data extraction complete.\")\n",
    "    \n",
    "    # 상위 5개 행 출력\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 함수 실행 예시\n",
    "df_metadata = extract_package_metadata(\"../data/package/neutral/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b25fd0-b8d5-41b2-b741-9c609fa9522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_duplicates(input_path=\"../data/metadata/raw/\", \n",
    "                     input_name=\"metadata.csv\", \n",
    "                     subset_columns=['name', 'version', 'rubygems_version'], \n",
    "                     output_path=\"../data/metadata/raw/\", \n",
    "                     output_name=\"checked_metadata.csv\", \n",
    "                     duplicates_output_path=\"../data/metadata/raw/duplicate_metadata.csv\"):\n",
    "    \"\"\"\n",
    "    메타데이터 파일에서 중복된 행을 확인하고 처리한 후 결과를 저장하는 함수.\n",
    "    \n",
    "    :param input_path: 데이터 파일이 저장된 입력 경로 (기본값: \"../data/metadata/raw/\")\n",
    "    :param input_name: 입력 파일 이름 (기본값: \"metadata.csv\")\n",
    "    :param subset_columns: 중복을 확인할 열들의 리스트 (기본값: ['name', 'version', 'rubygems_version'])\n",
    "    :param output_path: 중복 제거된 데이터를 저장할 경로 (기본값: \"../data/metadata/raw/\")\n",
    "    :param output_name: 중복 제거된 데이터를 저장할 파일 이름 (기본값: \"checked_metadata.csv\")\n",
    "    :param duplicates_output_path: 중복된 데이터를 저장할 경로 (기본값: \"../data/metadata/raw/duplicate_metadata.csv\")\n",
    "    \"\"\"\n",
    "    # 데이터 읽기\n",
    "    df = pd.read_csv(input_path + input_name)\n",
    "\n",
    "    # 중복된 행을 찾아 출력 및 DataFrame으로 저장\n",
    "    duplicates = df[df.duplicated(subset=subset_columns, keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        print(\"중복된 행의 정보:\")\n",
    "        print(duplicates[subset_columns])\n",
    "        \n",
    "        # 중복된 행을 별도의 파일로 저장\n",
    "        duplicates.to_csv(duplicates_output_path, index=False)\n",
    "        print(f\"중복된 메타데이터가 {duplicates_output_path}에 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"중복된 행이 없습니다.\")\n",
    "\n",
    "    # 중복된 행을 제거\n",
    "    df_checked = df.drop_duplicates(subset=subset_columns, keep='first')\n",
    "\n",
    "    # 중복 제거 전/후 행 개수 확인\n",
    "    print(f\"중복 제거 전 데이터프레임 크기: {df.shape}\")\n",
    "    print(f\"중복 제거 후 데이터프레임 크기: {df_checked.shape}\")\n",
    "\n",
    "    # 중복 제거된 데이터를 새로운 파일로 저장\n",
    "    df_checked.to_csv(output_path + output_name, index=False)\n",
    "    print(f\"중복 제거된 데이터가 {output_path + output_name}에 저장되었습니다.\")\n",
    "\n",
    "# 함수 호출 예시 (기본값으로 실행)\n",
    "check_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
